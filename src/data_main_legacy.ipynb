{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from modules.excel_mod import preprocess_legacy_data_from_excel\n",
    "from modules.transform_Georgia_mod import transform_column_names\n",
    "from modules.transform_Georgia_mod import preprocess_Georgia_data\n",
    "from modules.transform_Georgia_mod import create_patient_condition_table\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config from yaml file\n",
    "with open('../config/config.yml', 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "# Setting the path for the excel file found in the config file.\n",
    "file_path = config['Georgia_2250_file_path']\n",
    "file_paths = [file_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the sheets of interest from the excel file and into csv form\n",
    "# Run this once to create the csv files. \n",
    "file_number = '2250'\n",
    "month = 'november'\n",
    "target_sheet = 'November 2100-2250'\n",
    "# preprocess_legacy_data_from_excel(file_paths, file_number, month, target_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the dataframes that we want to process:\n",
    "df_november = pd.read_csv('../countries/Georgia/data/raw/Georgia_legacy_2250_1_november.csv')\n",
    "\n",
    "# To get the registration dates go to the sql_queries folder and use the query  \n",
    "# Don't forget to clean the csv file and keep only the columns that are relevant.\n",
    "CaseBrowser_prod_data = pd.read_csv('../countries/Georgia/data/raw/Casebrowser_prod_data_1-8-24.csv')\n",
    "registrationdate = CaseBrowser_prod_data[['patient_local_identifier', 'registrationdate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_november.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the third parameter depending on the values in the csv file or insert dataframe alone if there are no rows to drop\n",
    "# Pick back up here.\n",
    "rows_to_drop = [0,1,2]\n",
    "preprocess_Georgia_data(df_november, registrationdate, rows_to_drop, file_number, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the csv files in the intermediate directory and transform the column names\n",
    "# Then output the results into the processed directory\n",
    "interm_dir = '../countries/Georgia/data/intermediate'\n",
    "\n",
    "# A list of all the csv files in the intermediate directory\n",
    "csv_files = [file_name for file_name in os.listdir(interm_dir) if file_name.endswith('.csv')]\n",
    "\n",
    "# Filter files created today\n",
    "today = datetime.now().date()\n",
    "recent_csv_files = [file_name for file_name in csv_files if datetime.fromtimestamp(os.path.getctime(os.path.join(interm_dir, file_name))).date() == today]\n",
    "\n",
    "# Sort files based on creation time\n",
    "recent_csv_files.sort(key=lambda x: os.path.getctime(os.path.join(interm_dir, x)), reverse=True)\n",
    "\n",
    "# Process only the most recent files\n",
    "if recent_csv_files:\n",
    "    for csv_file in recent_csv_files:\n",
    "        file_path = os.path.join(interm_dir, csv_file)\n",
    "        transform_column_names(file_path)\n",
    "else:\n",
    "    print('No recently created files to process.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the patient and condition table\n",
    "\n",
    "* If the patient table in the database does not have the indentifiers in the processed data, then the patient data has to be added. \n",
    "\n",
    "* The same goes for the condition table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to save the dataframes into the processed directory for the patient and condition tables\n",
    "def gen_save(dataframes, month):\n",
    "    data_folder = '../countries/Georgia/data/processed/'\n",
    "    \n",
    "    index_labels = {1: 'patient', 2: 'condition'}\n",
    "    \n",
    "    # Loop through the dataframes list and save them \n",
    "    for idx, df in enumerate(dataframes, start=1):\n",
    "        csv_file_name = f'Georgia_{idx}_{month}'\n",
    "        \n",
    "        # Conditionally add the label based on the index\n",
    "        if idx in index_labels:\n",
    "            csv_file_name += f'_{index_labels[idx]}'\n",
    "        \n",
    "        csv_file_name += '.csv'\n",
    "        \n",
    "        csv_file_path = os.path.join(data_folder, csv_file_name)\n",
    "        df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_november = pd.read_csv('../countries/Georgia/data/processed/Georgia_2250_1_november_specimen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_condition_november = create_patient_condition_table(processed_november, CaseBrowser_prod_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tuples of the dataframes\n",
    "patient_condition_november[0].head(10) # *patient table*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_condition_november[1].head(10) # *condition table*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to make the tuples into individual dataframes\n",
    "november_patient = patient_condition_november[0]\n",
    "november_condition = patient_condition_november[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dataframes to save\n",
    "dataframes = [november_patient, november_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_save(dataframes, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv('../countries/Georgia/data/processed/Georgia_patient_november.csv')\n",
    "condition = pd.read_csv('../countries/Georgia/data/processed/Georgia_condition_november.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check file's for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a function that checks for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients[patients.duplicated(['gender', 'managingorganizationid', 'identifier'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition[condition.duplicated(['identifier', 'casedefinition','ageonset','registrationdate'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('Georgia/data/processed/Georgia_2250_1_november_specimen.csv')\n",
    "df_2 = pd.read_csv('Georgia/data/processed/Georgia_2250_2_november_culture.csv')\n",
    "df_3 = pd.read_csv('Georgia/data/processed/Georgia_2250_3_november_microscopy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[df_1.duplicated(['identifier', 'registrationdate','containeridentifier','collected','bodysite'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2[df_2.duplicated(['identifier', 'registrationdate','containeridentifier','issued','value', 'culturetype'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3[df_3.duplicated(['identifier', 'registrationdate','containeridentifier','issued','value','microscopytype'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates from files\n",
    "df_1.drop_duplicates(['identifier', 'registrationdate','containeridentifier','collected','bodysite'], inplace=True)\n",
    "df_2.drop_duplicates(['identifier', 'registrationdate','containeridentifier','issued','value','culturetype'], inplace=True)\n",
    "df_3.drop_duplicates(['identifier', 'registrationdate','containeridentifier','issued','value','microscopytype'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new dataframes\n",
    "df_1.to_csv('../countries/Georgia/data/processed/Georgia_2250_november_drop_dups_1.csv', index=False)\n",
    "df_2.to_csv('../countries/Georgia/data/processed/Georgia_2250_november_drop_dups_2.csv', index=False)\n",
    "df_3.to_csv('../countries/Georgia/data/processed/Georgia_2250_november_drop_dups_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NTM-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
